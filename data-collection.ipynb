{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04b0cca6",
   "metadata": {},
   "source": [
    "## Zbieranie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0cec8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Path where the TSV files are stored\n",
    "path_to_tsv_files = './datasets/*.tsv'\n",
    "\n",
    "# List to hold DataFrames with the specified column\n",
    "dataframes_with_column = []\n",
    "\n",
    "# The column of interest\n",
    "column_of_interest = '2018'\n",
    "\n",
    "# Function to preprocess the file content\n",
    "def preprocess_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # Read the file and replace tabs with commas\n",
    "        content = file.read().replace('\\t', ',')\n",
    "    return content\n",
    "\n",
    "# Loop through each TSV file in the directory\n",
    "for tsv_file in glob.glob(path_to_tsv_files):\n",
    "    try:\n",
    "        # Preprocess the file content\n",
    "        file_content = preprocess_file(tsv_file)\n",
    "\n",
    "        # Use StringIO to simulate a file object for pandas\n",
    "        df = pd.read_csv(StringIO(file_content))\n",
    "\n",
    "        # Strip spaces from column names\n",
    "        df.columns = df.columns.str.strip()\n",
    "\n",
    "        # Check if both the specified column and 'geo\\\\TIME_PERIOD' are in the DataFrame\n",
    "        if column_of_interest in df.columns and 'geo\\\\TIME_PERIOD' in df.columns:\n",
    "            # Keep only the '2018' column and 'geo\\\\TIME_PERIOD'\n",
    "            df = df[['geo\\\\TIME_PERIOD', column_of_interest]]\n",
    "            dataframes_with_column.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {tsv_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd638831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of 0 869\n",
      "len of 1 37\n",
      "len of 2 126\n",
      "len of 3 2329\n",
      "len of 4 23955\n",
      "len of 5 17646\n",
      "len of 6 3990\n",
      "len of 7 2244\n",
      "len of 8 95640\n",
      "len of 9 21713\n",
      "len of 10 3471\n",
      "len of 11 605767\n",
      "len of 12 744\n",
      "len of 13 26928\n"
     ]
    }
   ],
   "source": [
    "dataframes_with_column.pop(4)\n",
    "\n",
    "for i, df in enumerate(dataframes_with_column):\n",
    "    df['geo\\\\TIME_PERIOD'] = df['geo\\\\TIME_PERIOD'].astype('category')\n",
    "    if df['2018'].dtype == 'object':\n",
    "        df['2018'] = pd.to_numeric(df['2018'], errors='coerce')\n",
    "    print('len of', i, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b184a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged 2 of 14 DataFrames.\n",
      "Merged 3 of 14 DataFrames.\n",
      "Merged 4 of 14 DataFrames.\n",
      "Merged 5 of 14 DataFrames.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming dataframes_with_column is already filled with DataFrames\n",
    "if dataframes_with_column:\n",
    "    # Rename columns outside of the merge loop to prevent issues with index lookup\n",
    "    for i, df in enumerate(dataframes_with_column):\n",
    "        df.rename(columns={column_of_interest: f'col{i+1}'}, inplace=True)\n",
    "\n",
    "    # Start with the first DataFrame\n",
    "    merged_df = dataframes_with_column[0]\n",
    "\n",
    "    # Merge remaining DataFrames\n",
    "    for i in range(1, len(dataframes_with_column)):\n",
    "        merged_df = pd.merge(merged_df, dataframes_with_column[i], on='geo\\\\TIME_PERIOD', how='outer')\n",
    "        print(f\"Merged {i+1} of {len(dataframes_with_column)} DataFrames.\")\n",
    "\n",
    "    print(merged_df.head())  # Display the first few rows of the merged DataFrame\n",
    "else:\n",
    "    print(\"No dataframes contained the required columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dedff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5caf15b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source geo\\TIME_PERIOD    col1 col10   col11   col12 col13  col14  col15  \\\n",
      "0                   AL     NaN  0.6      NaN   3830    NaN  34.9   30.1    \n",
      "1                   AT     : u  0.0   13.0 u  37690    : u   7.9    8.6    \n",
      "2                   BA      :    NaN      :       :     :     NaN    NaN   \n",
      "3                   BE  48.1 u  0.3    21.2   35510     :   -3.1   15.9    \n",
      "4                   BG     : u  0.0      : u   6330    : u  12.2   11.1    \n",
      "\n",
      "source  col2    col3   col4   col5   col6    col7   col8   col9  \n",
      "0        NaN  23.46   62.0    207     NaN   1972     NaN   1.1   \n",
      "1       9.0   22.36   20.9   3157   24.8   24675   66.7    9.6   \n",
      "2         :      NaN    NaN    NaN     :      NaN     :     NaN  \n",
      "3       8.4   16.39   23.3   6141    7.7   23135   89.4   11.4   \n",
      "4       7.7    19.2   62.4    440     : u   3474   95.0   21.7   \n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Path where the TSV files are stored\n",
    "path_to_tsv_files = './datasets/*.tsv'\n",
    "\n",
    "# List to hold DataFrames with the specified column\n",
    "dataframes_with_column = []\n",
    "\n",
    "# The column of interest\n",
    "column_of_interest = '2018'\n",
    "\n",
    "# Function to preprocess the file content\n",
    "def preprocess_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # Read the file and replace tabs with commas\n",
    "        content = file.read().replace('\\t', ',')\n",
    "    return content\n",
    "\n",
    "# Loop through each TSV file in the directory\n",
    "for tsv_file in glob.glob(path_to_tsv_files):\n",
    "    try:\n",
    "        # Preprocess the file content\n",
    "        file_content = preprocess_file(tsv_file)\n",
    "\n",
    "        # Use StringIO to simulate a file object for pandas\n",
    "        df = pd.read_csv(StringIO(file_content))\n",
    "\n",
    "        # Strip spaces from column names\n",
    "        df.columns = df.columns.str.strip()\n",
    "\n",
    "        # Check if both the specified column and 'geo\\\\TIME_PERIOD' are in the DataFrame\n",
    "        if column_of_interest in df.columns and 'geo\\\\TIME_PERIOD' in df.columns:\n",
    "            # Keep only the '2018' column and 'geo\\\\TIME_PERIOD'\n",
    "            df = df[['geo\\\\TIME_PERIOD', column_of_interest]]\n",
    "            dataframes_with_column.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {tsv_file}: {e}\")\n",
    "\n",
    "# Concatenate all DataFrames with a unique identifier\n",
    "if dataframes_with_column:\n",
    "    for i, df in enumerate(dataframes_with_column):\n",
    "        df['source'] = f'col{i+1}'  # Add a unique identifier for each source DataFrame\n",
    "\n",
    "    # Concatenate all DataFrames vertically\n",
    "    combined_df = pd.concat(dataframes_with_column)\n",
    "\n",
    "    # Pivot the DataFrame to wide format\n",
    "    pivoted_df = combined_df.pivot_table(index='geo\\\\TIME_PERIOD', columns='source', values='2018', aggfunc='first').reset_index()\n",
    "\n",
    "    print(pivoted_df.head())  # Display the first few rows of the pivoted DataFrame\n",
    "else:\n",
    "    print(\"No dataframes contained the required columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ca2887f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source geo\\TIME_PERIOD    col1  col10   col11    col12  col13   col14   col15  \\\n",
      "0                   AL     NaN   0.6      NaN    3830     NaN   34.9    30.1    \n",
      "1                   AT     : u   0.0   13.0 u   37690     : u    7.9     8.6    \n",
      "2                   BA      :     NaN      :        :      :      NaN     NaN   \n",
      "3                   BE  48.1 u   0.3    21.2    35510      :    -3.1    15.9    \n",
      "4                   BG     : u   0.0      : u    6330     : u   12.2    11.1    \n",
      "5                   CH  45.0 u   0.1     7.6    61690     : u    9.4     8.0    \n",
      "6                   CY      :    0.4      : u   24500      :   42.2 u   27.9    \n",
      "7                   CZ     : u   0.0   16.5 u   17990      :   14.6 d    6.6    \n",
      "8                   DE   39.3    0.1     7.3    35650      :     7.1    11.6    \n",
      "9                   DK     : u   0.6    11.3    48450      :    17.4    12.4    \n",
      "10                  EA     NaN  0.1 e     NaN   30910     NaN     NaN  12.8 e   \n",
      "11                EA12     NaN    NaN     NaN   31590     NaN     NaN     NaN   \n",
      "12                EA17     NaN    NaN     NaN      NaN    NaN     NaN     NaN   \n",
      "13                EA18     NaN   0.1      NaN      NaN    NaN     NaN   12.8    \n",
      "14                EA19     NaN   0.1      NaN   30910     NaN   15.3    12.8    \n",
      "15                EA20   37.5    0.1    17.9    30690     : u   15.3      NaN   \n",
      "16                  EE     : u   0.0      : u   14920      :    29.6    12.1    \n",
      "17                  EL     : u   0.2   78.2 u   17430     : u    5.3    15.4    \n",
      "18                  ES     : u   0.0    56.4    24890     : u  -16.1    14.5    \n",
      "19                  EU     NaN   0.1      NaN      NaN    NaN     NaN  12.3 e   \n",
      "20                EU15     NaN    NaN     NaN   32310     NaN     NaN     NaN   \n",
      "21           EU27_2007     NaN   0.1      NaN      NaN    NaN     NaN  12.3 e   \n",
      "22           EU27_2020   38.9   0.1 e   18.5    27620   34.0    14.4   12.3 e   \n",
      "23                EU28     NaN   0.1      NaN   28270     NaN   15.3   12.3 e   \n",
      "24                  FI     : u   0.0    27.6    36740     : u   14.0     3.4    \n",
      "25                  FR  40.2 u   0.2    34.2    32800     : u   17.2    11.3    \n",
      "26                  HR      :    0.3      : u   12310      :     4.0    13.0    \n",
      "27                  HU     : u   0.4      : u   12690      :    16.8    22.2    \n",
      "28                  IE  46.8 u   0.0    28.7    57610      :     5.4    12.3    \n",
      "29                  IS     : u   1.1      : u   39090      :    15.8    17.8    \n",
      "30                  IT    : bu   0.1   57.4 b   27030    : bu    2.0    14.3    \n",
      "31                  LI     NaN    NaN     NaN  146100     NaN     NaN     NaN   \n",
      "32                  LT     : u   0.0      : u   13400      :     6.9    12.0    \n",
      "33                  LU     : u   0.0      : u   83390     : u     : c   15.7    \n",
      "34                  LV     : u   0.0      : u   12140      :    12.0    15.5    \n",
      "35                  ME     : u   0.0      : u    6230     : u      :    30.8    \n",
      "36                  MK      :    0.4      : u   4540 e  45.3       :    16.0    \n",
      "37                  MT     : u   0.0      : u   22550      :   28.9 u    6.8    \n",
      "38                  NL   40.6    0.0    10.1    41450      :    15.5    16.4    \n",
      "39                  NO     : u   0.0   13.5 u   69840      :     6.5     3.5    \n",
      "40                  PL  50.0 u   0.1      : u   12500     : u   20.0     7.1    \n",
      "41                  PT     : u   0.2      : u   18190      :    -4.7    25.3    \n",
      "42                  RO     : u   0.2      : u    8910   31.7    -2.9     8.8    \n",
      "43                  RS     : u   0.6   45.0 u    5200     : u   -5.9    14.5    \n",
      "44                  SE    : bu   0.3   30.1 b   43760      :     8.4     6.2    \n",
      "45                  SI  50.0 u   0.0      : u   20240      :    14.6    18.9    \n",
      "46                  SK     : u   0.1      : u   15580      :    21.5     4.8    \n",
      "47                  TR   20.7    0.2    14.3    11570   42.0       :    30.8    \n",
      "48                  UK   45.1    0.0    24.2    32640      :     1.1   13.1 u   \n",
      "49                  XK     NaN   0.1      NaN    12.3     NaN     NaN   15.3    \n",
      "\n",
      "source    col2    col3    col4    col5    col6     col7    col8    col9  \n",
      "0          NaN  23.46    62.0     207      NaN    1972      NaN    1.1   \n",
      "1         9.0   22.36    20.9    3157    24.8    24675    66.7     9.6   \n",
      "2           :      NaN     NaN     NaN      :       NaN      :      NaN  \n",
      "3         8.4   16.39    23.3    6141     7.7    23135    89.4    11.4   \n",
      "4         7.7    19.2    62.4     440      : u    3474    95.0    21.7   \n",
      "5         9.1   13.79    19.9      : c   46.6    42253    46.7     9.6   \n",
      "6        10.4   21.88    39.1    3138      : u   15199    90.6    12.7   \n",
      "7        15.2   19.36    28.7     919     2.1     8802    94.9     8.0   \n",
      "8         8.0    26.2    24.5      : c   20.1    22081    73.7    14.5   \n",
      "9         7.0   10.23    25.2    4567    42.4    29611    49.9    10.1   \n",
      "10         NaN     NaN  30.1 e     NaN     NaN  18807 e     NaN  13.3 e  \n",
      "11         NaN     NaN     NaN     NaN     NaN      NaN     NaN     NaN  \n",
      "12         NaN  18.56       :    2688      NaN      NaN     NaN     NaN  \n",
      "13         NaN  18.63    30.0    2688      NaN   18915      NaN   13.4   \n",
      "14         NaN  18.69    30.1    2688      NaN   18807      NaN   13.3   \n",
      "15       10.8      NaN   30.2      NaN   11.4    18658    82.6      NaN  \n",
      "16        6.0   27.46    29.9    3500    11.8    10171    80.6     8.3   \n",
      "17       21.6   20.78    53.8    1500      : u    7781    95.7    14.1   \n",
      "18       12.1   18.93    32.5    1721     4.7    14492    89.8    12.2   \n",
      "19         NaN     NaN   31.2      NaN     NaN  17009 e     NaN  13.3 e  \n",
      "20         NaN     NaN      :      NaN     NaN       :      NaN     NaN  \n",
      "21         NaN  18.74    31.1   2688 s     NaN   17096      NaN  13.3 e  \n",
      "22       11.3   18.21   31.2 e  2688 s   10.6   16437 e   83.6   12.7 e  \n",
      "23         NaN      :    31.2       :      NaN   17009      NaN  13.3 e  \n",
      "24        3.8    6.42    32.9    4434    23.1    24012    62.8     9.0   \n",
      "25        6.4   11.31    29.5    2744     3.0    21975    88.7    15.3   \n",
      "26       10.2   23.07    58.7     703      : u    6545    88.7     4.1   \n",
      "27       10.7   12.31    23.7     673    1.6 u    5323    94.1     5.2   \n",
      "28       12.3   22.63    26.8    4457     8.8    24336    77.3     8.3   \n",
      "29        6.3   12.18    37.1    5644    73.5    39603    21.2     1.9   \n",
      "30      19.7 b  10.25    36.7      : c   1.2 b   16511   94.5 b   10.2   \n",
      "31         NaN     NaN     NaN     NaN     NaN      NaN     NaN     NaN  \n",
      "32        2.3   23.44    46.8     580    3.2 u    6652    92.5     4.5   \n",
      "33        8.0   15.94    16.1    2224     8.0    33716    88.4    15.0   \n",
      "34        4.3   27.69    51.6     650    4.4 u    6989    92.5    11.5   \n",
      "35       13.8       :    74.2       :      : u    3757    91.5     8.7   \n",
      "36       21.4   17.98    71.7     431      : u    2624    93.6     5.8   \n",
      "37       22.3   17.62    11.6    1453   15.4 u   14581    69.0     9.8   \n",
      "38        9.6   19.61    31.7    2493    56.2    23441    35.4    18.8   \n",
      "39        3.9   10.35    23.4    3325    31.1    38771    61.4     4.5   \n",
      "40       13.8   23.47    41.9     704     2.2     6460    94.7     4.4   \n",
      "41        6.6    4.69    35.1     906     2.8     9203    91.3     7.7   \n",
      "42       18.5    17.8    49.6     494     4.6     3229    91.8    13.6   \n",
      "43       15.4   18.12    47.4     327    1.1 u    2706    93.0    18.8   \n",
      "44       4.7 b   4.42    20.8    3802   24.6 b   25054   60.0 b   14.5   \n",
      "45        7.1   19.41    35.5      : c   7.1 u   13030    87.5     9.8   \n",
      "46        8.5   19.18    41.7     831    2.3 u    7427    93.3     5.5   \n",
      "47       40.8    0.78    24.6     526    13.5     3445    82.1     8.1   \n",
      "48         NaN  21.46    31.1    2413    24.2    20868    63.7   20.4 u  \n",
      "49         NaN     NaN   47.2      NaN     NaN    2010      NaN    3.0   \n"
     ]
    }
   ],
   "source": [
    "print(pivoted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff90eecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
